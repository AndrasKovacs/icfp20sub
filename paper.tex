
%% build: latexmk -pdf -pvc -xelatex paper.tex

%% For double-blind review submission, w/o CCS and ACM Reference (max submission space)
\documentclass[acmsmall,review,anonymous,prologue,dvipsnames]{acmart}\settopmatter{printfolios=true,printccs=false,printacmref=false}
%% For double-blind review submission, w/ CCS and ACM Reference
%\documentclass[acmsmall,review,anonymous]{acmart}\settopmatter{printfolios=true}
%% For single-blind review submission, w/o CCS and ACM Reference (max submission space)
%\documentclass[acmsmall,review]{acmart}\settopmatter{printfolios=true,printccs=false,printacmref=false}
%% For single-blind review submission, w/ CCS and ACM Reference
%\documentclass[acmsmall,review]{acmart}\settopmatter{printfolios=true}
%% For final camera-ready submission, w/ required CCS and ACM Reference
%\documentclass[acmsmall]{acmart}\settopmatter{}


%% Journal information
%% Supplied to authors by publisher for camera-ready submission;
%% use defaults for review submission.
\acmJournal{PACMPL}
\acmVolume{1}
\acmNumber{CONF} % CONF = POPL or ICFP or OOPSLA
\acmArticle{1}
\acmYear{2018}
\acmMonth{1}
\acmDOI{} % \acmDOI{10.1145/nnnnnnn.nnnnnnn}
\startPage{1}

%% Copyright information
%% Supplied to authors (based on authors' rights management selection;
%% see authors.acm.org) by publisher for camera-ready submission;
%% use 'none' for review submission.
\setcopyright{none}
%\setcopyright{acmcopyright}
%\setcopyright{acmlicensed}
%\setcopyright{rightsretained}
%\copyrightyear{2018}           %% If different from \acmYear

%% Bibliography style
\bibliographystyle{ACM-Reference-Format}
%% Citation style
%% Note: author/year citations are required for papers published as an
%% issue of PACMPL.
\citestyle{acmauthoryear}   %% For author/year citations


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Note: Authors migrating a paper from PACMPL format to traditional
%% SIGPLAN proceedings format must update the '\documentclass' and
%% topmatter commands above; see 'acmart-sigplanproc-template.tex'.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%% Some recommended packages.
\usepackage{booktabs}   %% For formal tables:
                        %% http://ctan.org/pkg/booktabs
\usepackage{subcaption} %% For complex figures with subfigures/subcaptions
                        %% http://ctan.org/pkg/subcaption


%% ------------------------------------------------------------

\usepackage{xcolor}
\usepackage{mathpartir}
\usepackage{todonotes}
\presetkeys{todonotes}{inline}{}
\usepackage{scalerel}
\usepackage{cleveref}

\newcommand{\slet}{\boldsymbol{\mathsf{let}}}
\renewcommand{\sin}{\boldsymbol{\mathsf{in}}}
\renewcommand{\U}{\mathsf{U}}
\newcommand{\emptycon}{\scaleobj{.75}\bullet}
\newcommand{\To}{\Rightarrow}
\newcommand{\p}{\mathsf{p}}
\newcommand{\id}{\mathsf{id}}
\newcommand{\blank}{\mathord{\hspace{1pt}\text{--}\hspace{1pt}}}
\newcommand{\freshMeta}[3]{\mathsf{freshMeta}\,#1\,#2\,#3}
\newcommand{\unify}{\mathsf{unify}}
\newcommand{\fail}{\mathsf{fail}}
\newcommand{\kw}[1]{{\mathsf{#1}}}

\newcommand{\echeckblank}{\llbracket\blank\rrbracket\!\Downarrow}
\newcommand{\einferblank}{\llbracket\blank\rrbracket\!\Uparrow}
\newcommand{\echeck}[4]{\llbracket#1\rrbracket\!\Downarrow\,#2\,#3\,#4}
\newcommand{\einfer}[4]{\llbracket#1\rrbracket\!\Uparrow\,#2\,#3\,#4}
\newcommand{\echeckt}[2]{\llbracket#1\rrbracket\!\Downarrow\,#2}
\newcommand{\einfert}[2]{\llbracket#1\rrbracket\!\Uparrow\,#2}
\newcommand{\edo}{\boldsymbol{\mathsf{do}}}
\newcommand{\ereturn}{\boldsymbol{\mathsf{return}}}
\newcommand{\eif}{\boldsymbol{\mathsf{if}}}
\newcommand{\ethen}{\boldsymbol{\mathsf{then}}}
\newcommand{\eelse}{\boldsymbol{\mathsf{else}}}
\newcommand{\ecase}{\boldsymbol{\mathsf{case}}}
\newcommand{\eof}{\boldsymbol{\mathsf{of}}}
\newcommand{\true}{\mathsf{true}}
\newcommand{\false}{\mathsf{false}}
\newcommand{\einsert}[5]{\mathsf{insert}\,#1\,#2\,#3\,#4\,#5}
\newcommand{\Set}{\mathsf{Set}}

\newcommand{\Nat}{\mathsf{Nat}}
\newcommand{\zero}{\mathsf{zero}}
\newcommand{\suc}{\mathsf{suc}}

\theoremstyle{remark}
\newtheorem{notation}{Notation}

%% ------------------------------------------------------------


\begin{document}

%% Title information
\title{Elaboration with First-Class Implicit Function Types}


%% Author with single affiliation.
\author{Andr{\'a}s Kov{\'a}cs}
\orcid{0000-0002-6375-9781}
\affiliation{
  \department{Department of Programming Languages and Compilers}
  \institution{E{\"o}tv{\"o}s Lor{\'a}nd University}
  \city{Budapest}
  \country{Hungary}
}
\email{kovacsandras@inf.elte.hu}


\begin{abstract}
Implicit functions are dependently typed functions, such that arguments are
provided (by default) by inference machinery instead of programmers of the
surface language. Implicit functions in Agda are an archetypal example. In the
Haskell language as implemented by the Glasgow Haskell Compiler (GHC),
polymorphic types are another example. Implicit function types are
\emph{first-class} if they are treated as any other type in the surface
language. This holds in Agda and partially holds in GHC. Inference and
elaboration in the presence of first-class implicit functions poses a challenge;
in the context of GHC and ML-like languages, this has been dubbed
``impredicative instantiation'' or ``impredicative inference''. We propose a new
framework for elaborating first-class implicit functions, which is applicable
for full dependent type theories and compares favorably to prior solutions in
terms of power, generality and conceptual simplicity. We build atop Norell's
bidirectional elaboration algorithm for Agda, and note that the key issue is
incomplete information about insertions of implicit abstractions and
applications. We make it possible to track and refine information related to
such insertions, by adding a new function type to a core Martin-L\"of type
theory, which supports strict (definitional) currying. This allows us to
represent undetermined domain arities of implicit function types, and we can
decide at any point during elaboration whether implicit abstractions should be
inserted.
\end{abstract}


%% 2012 ACM Computing Classification System (CSS) concepts
%% Generate at 'http://dl.acm.org/ccs/ccs.cfm'.
\begin{CCSXML}
<ccs2012>
<concept>
<concept_id>10011007.10011006.10011008</concept_id>
<concept_desc>Software and its engineering~General programming languages</concept_desc>
<concept_significance>500</concept_significance>
</concept>
<concept>
<concept_id>10003456.10003457.10003521.10003525</concept_id>
<concept_desc>Social and professional topics~History of programming languages</concept_desc>
<concept_significance>300</concept_significance>
</concept>
</ccs2012>
\end{CCSXML}

\ccsdesc[500]{Software and its engineering~General programming languages}
\ccsdesc[300]{Social and professional topics~History of programming languages}
%% End of generated code

%% Keywords
%% comma separated list
\keywords{impredicative polymorphism, type theory, elaboration, type inference}
\maketitle


\section{Introduction}
\label{sec:introduction}

Programmers and users of proof assistants do not like to write out obvious
things. Type inference and elaboration serve the purpose of filling in tedious
details, translating terse surface-level languages to explicit core
languages. Modern compilers such as Agda have gotten quite adept at this
task. However, in practice, programmers still have to tell the compiler when and
where to try filling in details on its own.

\textbf{Implicit function types} are a common mechanism for conveying to the
compiler that particular function arguments should be inferred by default. In
Agda and Coq, one can use bracketed function domains for this purpose:
\begin{alignat*}{3}
  & id : \{A : \kw{Set}\}\to A \to A \hspace{5em} \kw{Definition}\,id\,\{A : \kw{Type}\}(x : A) := x.\\
  & id\,x = x
\end{alignat*}
In GHC, one can use $\kw{forall}$ to define implicit function
types\footnote{This notation requires language extensions
  $\mathsf{KindSignatures}$ and $\mathsf{RankNTypes}$; one could also write the type
  $a \to a$ and GHC would silently insert the quantification.}
\begin{alignat*}{3}
  & id :: \kw{forall}\,(a :: \kw{*}).\,a \to a\\
  & id\,x = x
\end{alignat*}
In all of the above cases, if we apply $id$ to an argument, the implicit type
argument is provided by elaboration. For example, in Agda, $id\,true$ is
elaborated to $id\,Bool\,true$, and analogously in GHC and Coq. In all three
systems, there is also a way to explicitly specify implicit arguments: in Agda
we may put arguments in brackets as we have seen, in Coq we can prefix a name
with $\kw{@}$ to make every implicit argument explicit, as in
$\kw{@}id\,bool\,true$, and in GHC we can enable the language extension
$\mathsf{TypeApplications}$ and write $id\,\kw{@}Bool\,True$.

Implicit functions are \textbf{first-class} if they can be manipulated like any
other type. Coq is an example for a system where this is \emph{not} the case.
In Coq, the core language does not have an actual implicit function type,
instead, implicitness is tied to particular \emph{names}, and while we can write
$list\,(\kw{forall}\,\{A : \kw{Type}\},\,A\to A)$ for a list type of polymorphic
functions, the brackets here are simply ignored by Coq and we get a plain
function type. For example, Coq accepts the following definition:
\begin{alignat*}{3}
  & \kw{Definition}\,poly\,: \kw{forall}\,(f : \kw{forall}\,\{A : \kw{Type}\},\,A\to A),\,bool\,*\,nat :=\\
  & \quad \kw{fun}\,f \Rightarrow (f\,bool\,true,\,f\,nat\,0)
\end{alignat*}
This is a higher-rank polymorphic function which returns a pair. Note that $f$
is applied to two arguments, because the implicitness in $\kw{forall}\,\{A :
\kw{Type}\},\,A\to A$ is silently dropped.

In GHC Haskell, $\kw{forall}$ types are more flexible. We can write the
following, with $\kw{RankNTypes}$ enabled:
\begin{alignat*}{3}
  & poly :: (\kw{forall}\,a.\,a \to a) \to (Bool,\,Int) \\
  & poly\,f = (f\,True,\,f\,0)
\end{alignat*}
However, polymorphic types are only supported in function domains and as fields
of algebraic data constructors. We cannot instantiate an arbitrary type
parameter to a $\kw{forall}$, as in $[\kw{forall}\,a.\,a\to a]$ for a list type
with polymorphic elements. While this type is technically allowed by the
$\kw{ImpredicativeTypes}$ language extension, as of GHC 8.8 this extension is
deprecated and is not particularly usable in practice.

In Agda, implicit functions are truly a first-class notion, and we may have
$List\,(\{A : \kw{Set}\}\to A \to A)$ without issue. However, Agda's elaboration
still has limitations when it comes to handling implicit functions. Assume that
we have $[]$ for the empty list and $\blank::\blank$ for list extension,
and consider the following code:
\begin{alignat*}{3}
  & polyList : List\,(\{A : \kw{Set}\}\to A \to A)\\
  & polyList = (\lambda\,x \to x)\,::\,[]
\end{alignat*}
Agda 2.6.0.1 does not accept this. However, it does accept $polyList =
(\lambda\,\{A\}\,x \to x)\,::\,[]$. The issue is the following. Agda first
\emph{infers} a type for $(\lambda\,x \to x)\,::\,[]$, then tries to unify the
inferred type with the given $List\,(\{A : \kw{Set}\}\to A \to A)$
annotation. However, when Agda elaborates $\lambda\,x \to x$, it does not yet
know anything about the element type of the list; it is an undetermined
unification variable. Hence, Agda does not know whether it should insert an
extra $\lambda\,\{A\}$ or not. If the element type is later found to be an
implicit function, then it should, otherwise it should not. To solve this
conundrum, Agda simply assumes that any unknown type is \emph{not} an implicit
function type, and elects to not insert a lambda. This assumption is often
correct, but sometimes --- as in the current case --- it is not.

There is significant literature on type inference in the presence of first-class
polymorphic types, mainly in relation to GHC and ML-like languages \cite{TODO}.
The above issue in Agda is a specific instance of the challenges described in
the mentioned works. However, none of the proposed algorithms have landed so far
in production compilers, for reasons of complexity, fragility and interaction
with other language features.

The solution presented in this paper is to gradually accummulate information
about implicit insertions, and to have a setup where insertions can be refined
and performed at any time after a particular expression is elaborated. In the
current example, our algorithm wraps $\lambda\,x\to x$ in an implicit lambda
with unknown arity, whose domain is later refined to be $A : \kw{Set}$ when the
inferred type is unified with the annotation.

\subsection{Contributions}
\begin{itemize}
  \item We propose an elaboration algorithm which translates from a small
    Agda-like surface language to a small Martin-L\"of type theory extended with
    implicit function types, telescopes and \emph{strictly curried} function
    types with telescope domain. The extensions to the target theory are modest
    and are derivable from W-types. We use these extensions to accummulate
    information about implicit insertions.
  \item Our algorithm is a conservative extension of Norell's bidirectional
    elaborator for Agda \cite[Chapter~3]{norell07thesis}; it accepts strictly more
    programs, and does not require new constructs in the surface language.
  \item Our target language serves as a general platform for elaborating
    implicit functions. The concrete elaborator presented in this paper is a
    relatively simple one, and there is plenty of room to develop more advanced
    elaboration and unification. However, our simple algorithm is already
    comparable or superior to previous solutions for impredicative inference.
  \item We provide an executable implementation of the elaborator described in
    this paper.
\end{itemize}

\subsubsection{Note on terminology}

We prefer to avoid the term ``impredicative inference'' in order to avoid
confusion with impredicativity in type theory. The two notions sometimes
coincided historically, but currently they are largely orthogonal. In type
theory, impredicativity is a property of a universe, i.e.\ closure of a universe
under arbitrary products. In the type inference literature, impredicativity
means the ability to instantiate type variables and metavariables to polymorphic
types. In particular, we have that
\begin{itemize}
  \item Agda has type-theory-predicative universes, but implements
    type-inference-impredicative elaboration with first-class implicit function
    types.
  \item Coq has type-theory-impredicative $\kw{Prop}$ universe (and optionally
    also $\kw{Set}$), but implements type-inference-predicative elaboration,
    because of the lack of implicit function types.
  \item GHC is type-theory-impredicative with $\kw{RankNTypes}$ enabled and
    $\kw{ImpredicativeTypes}$ \emph{disabled}, as we have $(\kw{forall}\,(a :: *).\, a
    \to a) :: *$.
\end{itemize}

\section{Basic Bidirectional Elaboration}
\label{sec:basic_bidirectional_elaboration}

First, we present a variant of Norell's bidirectional elaborator
\cite[Chapter~3]{norell07thesis}. Compared to ibid.\ we make some extensions and
simplifications; what we end up with can be viewed as a toy version of the
actual Agda elaborator. In this section, we use it to illustrate the key issues,
and we extend it in Section TODO with additional rules.
\begin{figure}[h]
\begin{alignat*}{4}
  t,\,u,\,v,\,A,\,B,\,C\, :&:=\quad  && x\hspace{8em}              & \text{variable}                 &  \\
                           & |       && (x : A)\to B               & \text{function type}            &  \\
                           & |       && \{x : A\}\to B             & \text{implicit function type}   &  \\
                           & |       && t\,u                       & \text{application}              &  \\
                           & |       && t\,\{u\}                   & \text{implicit application}     &  \\
                           & |       && \lambda\,x.\, t            & \text{lambda abstraction}       &  \\
                           & |       && \lambda\,\{x\}.\,t         & \text{implicit abstraction}     &  \\
                           & |       && \U                         & \text{universe}                 &  \\
                           & |       && \slet\,x : A = t\,\sin\, u & \text{let-definition}           &  \\
                           & |       && \_                         & \text{hole for inferred term}   &
\end{alignat*}
\caption{Syntax of the surface language.}
\label{fig:surface}
\end{figure}

\begin{figure}

\begin{alignat*}{2}
  & \boxed{\Theta\vdash}\hspace{6em}           && \text{\emph{metacontext formation}}\\
  & \boxed{\Theta|\Gamma\vdash}                && \text{\emph{context formation}}\\
  & \boxed{\Theta|\Gamma\vdash t : A}          && \text{\emph{typing}}\\
  & \boxed{\Theta|\Gamma\vdash t \equiv u : A} && \text{\emph{term equality}}
\end{alignat*}

\begin{mathpar}
  \inferrule*[lab=metacon/empty]
             {\\}
             {\emptycon \vdash}

  \inferrule*[lab=metacon/bind]
             {\Theta \vdash \\ \Theta \vdash A : \U}
             {\Theta, \alpha : A \vdash}

  \inferrule*[lab=con/empty]
             {\Theta \vdash}
             {\Theta|\emptycon \vdash}

  \inferrule*[lab=con/bind]
             {\Theta|\Gamma \vdash \\ \Theta|\Gamma \vdash A : \U}
             {\Theta|\Gamma,\,x : A \vdash}

  \inferrule*[lab=con/define]
             {\Theta|\Gamma \vdash \\ \Theta|\Gamma \vdash t : A}
             {\Theta|\Gamma,\,x : A = t \vdash}

  \inferrule*[lab=tm/metavar]
             {\\}
             {\Theta_0,\,\alpha : A,\,\Theta_1|\Gamma \vdash \alpha : A}

  \inferrule*[lab=tm/bound-var]
             {\\}
             {\Theta|\Gamma,\,x : A,\,\Delta \vdash x : A}

  \inferrule*[lab=tm/defined-var]
             {\\}
             {\Theta|\Gamma,\,x : A = t,\,\Delta \vdash x : A}

  \inferrule*[lab=ty/u]
             {\\}
             {\Theta|\Gamma \vdash \U : \U}

  \inferrule*[lab=let]
             {\Theta|\Gamma\vdash t : A \\ \Theta|\Gamma,\,x : A = t \vdash u : B}
             {\Theta|\Gamma\vdash \slet\,x : A = t\,\sin\,u : B[x\mapsto t]}

  \inferrule*[lab=ty/fun]
             {\Theta|\Gamma \vdash A : \U \\ \Theta|\Gamma,\,x : A \vdash B : \U}
             {\Theta|\Gamma \vdash (x : A) \to B : \U}

  \inferrule*[lab=ty/implicit-fun]
             {\Theta|\Gamma \vdash A : \U \\ \Theta|\Gamma,\,x : A \vdash B : \U}
             {\Theta|\Gamma \vdash \{x : A\} \to B : \U}

  \inferrule*[lab=tm/app]
             {\Theta|\Gamma \vdash t : (x : A) \to B \\ \Theta|\Gamma\vdash u : A}
             {\Theta|\Gamma \vdash t\,u : B[x \mapsto u]}

  \inferrule*[lab=tm/implicit-app]
             {\Theta|\Gamma \vdash t : \{x : A\} \to B \\ \Theta|\Gamma\vdash u : A}
             {\Theta|\Gamma \vdash t\,\{u\} : B[x \mapsto u]}

  \inferrule*[lab=tm/lam]
             {\Theta|\Gamma,\,x : A \vdash t : B}
             {\Theta|\Gamma \vdash \lambda\,x.\,t : (x : A) \to B}

  \inferrule*[lab=tm/implicit-lam]
             {\Theta|\Gamma,\,x : A \vdash t : B}
             {\Theta|\Gamma \vdash \lambda\,\{x\}.\,t : \{x : A\} \to B}

  \inferrule*[lab=fun-$\beta$]
             {\Theta|\Gamma,\,x : A \vdash t : B \\\Theta|\Gamma\vdash u : A }
             {\Theta|\Gamma\vdash (\lambda\,x.\,t)\,u \equiv t[x\mapsto u] : B[x\mapsto u]}

  \inferrule*[lab=implicit-fun-$\beta$]
             {\Theta|\Gamma,\,x : A \vdash t : B \\\Theta|\Gamma\vdash u : A }
             {\Theta|\Gamma\vdash (\lambda\,\{x\}.\,t)\,\{u\} \equiv t[x\mapsto u] : B[x\mapsto u]}

  \inferrule*[lab=fun-$\eta$]
             {\Theta|\Gamma\vdash t : (x : A)\to B}
             {\Theta|\Gamma\vdash (\lambda\,x.\,t\,x) \equiv t : (x : A)\to B}

  \inferrule*[lab=implicit-fun-$\eta$]
             {\Theta|\Gamma\vdash t : \{x : A\}\to B}
             {\Theta|\Gamma\vdash (\lambda\,\{x\}.\,t\,\{x\}) \equiv t : \{x : A\}\to B}

  \inferrule*[lab=definition]
             {\\}
             {\Theta|\Gamma,\,x : A = t,\,\Delta \vdash x \equiv t : A}
\end{mathpar}
\caption{Selected rules of the core language.}
\label{fig:plaincore}
\end{figure}

\subsection{Surface syntax}
Figure \ref{fig:surface} shows the the possible constructs in the surface
language. We only have terms, as we have Russell-style universe in the core, and
we can conflate types and terms for convenience. The surface syntax does not
have semantics or any well-formedness relations attached; its sole purpose is to
serve as input to elaboration. Hence, the surface syntax can be also viewed as
a minimal untyped tactic language, which is interpreted by the elaborator.

The syntactic constructs are the almost the same in the surface language as in
the core syntax. The difference is that $\_$ holes only appear in surface
syntax. The $\_$ can be used to request a term to be inferred by elaboration,
the same way as in Agda.  This can be used to give let-definitions without type
annotation, as in $\slet\,x : \_ = \U\,\sin\,x$.

\subsection{Core syntax}

Figure \ref{fig:plaincore} lists selected rules of the core language. We avoid a
fully formal presentation in this paper. Some notes on what is elided:
\begin{itemize}
  \item We use nameful notation and implicit weakening, i.e.\ whenever a term is
    well-formed in some context, it is assumed to be well-formed (as it is) in
    extended contexts. We also assume that any specifically mentioned name is
    fresh, e.g.\ when we write $\Theta,\,\alpha : A$, we assume that $\alpha$ is
    fresh in $\Theta$.  Formally, we would use de Bruijn indices for variables,
    and define variable renaming and parallel substitution by recursion on
    presyntax, e.g.\ as in \cite{schafer2015autosubst}.
  \item Fixing any $\Theta$ metacontext, parallel substitutions of bound and
    defined variables form morphisms of a category, where the identity
    substitution $\id$ maps each variable to itself and composition
    $\blank\circ\blank$ is given by pointwise substitution. The action of
    parallel substitution on terms is functorial, i.e.\ $t[\sigma][\delta]
    \equiv t[\sigma\circ\delta]$ and $t[\id] \equiv t$, and typing is stable
    under substitution.
  \item
    Definitional equality is understood to be a congruence and an equivalence relation,
    which is respected by substitution and typing.
  \item
    We elide a number of well-formedness assumptions in rules. For instance, whenever
    a context appears in a rule, it is assumed to be well-formed. Likewise, whenever
    we have $\Theta|\Gamma\vdash t : A$, we assume that $\Theta|\Gamma\vdash A : \U$.
\end{itemize}

From now on, we will only consider well-formed core syntax, and only
constructions which respect definitional equality. In other words, we quotient
well-formed syntax by definitional equality.

Alternatively, one could present the syntax as a generalized algebraic theory
\cite{sterling2019algebraic} or a quotient inductive-inductive type
\cite{ttintt}, in which case we would get congruences and quotienting for free,
and we would also get a rich model theory for our syntax. However, it seems that
there are a number of possible choices for giving an algebraic presentation of
metacontexts, and existing works on algebraic presentations of dependent modal
contexts (e.g.\ \cite{birkedal2018modal}, TODO) do not precisely cover the
current use case. We leave this to future work, along with the investigation of
elaboration from an algebraic perspective.

\todo{how to refer to mathpartir rules from text?}

Metacontexts are used to record metavariables which are created during
elaboration. In our case, metacontexts are simply a context prefix, and we have
variables pointing into it. This corresponds to a particularly simple variant of
\emph{crisp type theory} \cite{licata2018internal}, where we do not have modal
type operators or functions with crisp (``meta'') domain. The non-meta typing context
additionally supports \emph{defined variables}, which is used in the typing rule
for \emph{let-definitions}, and we have that any defined variable is equal to
its definition. We mainly support this as a convenience feature in the
implementation of our elaborator.

The universe $\U$ is Russell-style, and we have the type-in-type rule.
This causes our core syntax to be non-total, and our elaboration algorithm to be
possibly non-terminating. We use type-in-type to simplify presentation, since
consistent universe setups are orthogonal to the focus of this work.

Function types only differ from each other in notation: implicit
functions have the same rules as ``explicit'' functions. The primary purpose of
implicit function types is to \emph{guide elaboration}: the elaborator will at
times compute a type and branch on whether it is an implicit function.

\begin{notation}
Both in the surface and core syntax, we use Agda-like notation:
\begin{itemize}
  \item We use $A \to B$ to refer to non-dependent functions.
  \item We group domain types together in functions, and omit function arrows,
    as in $\{A\,B : \U\}(x : A) \to B \to A$.
  \item We group multiple $\lambda$-s, as in $\lambda\,\{A\}\,\{B\}\,x\,y.\,x$.
\end{itemize}
\end{notation}

\begin{notation}\label{not:spines}
  We sometimes use a spine notation for neutral terms. A spine is a list of
  terms, noted as $\overline{t}$, where terms may be wrapped in brackets to
  signal implicit application. For example, if $\overline{u} \equiv
  (\{A\},\,\{B\},\,x)$, then $t\,\overline{u}$ denotes $t\,\{A\}\,\{B\}\,x$.  In
  $t\,\overline{u}$, we call $t$ the \emph{head} of the neutral term. In
  particular, if $t$ is a metavariable, the neutral term is \emph{meta-headed}.
\end{notation}

\begin{example}
The core syntax is quite expressive as a programming language, thanks to
let-definitions and the type-in-type rule which allows Church-encodings of a
large class of inductive types. For example, the following term computes a list
of types, by mapping over the list $cons\,\U\,(cons\,\U\,nil)$.
\begin{alignat*}{3}
  & \slet\,List : \U\to\U\\
  & \hspace{1em}= \lambda\,A.\,(L : \U)\to(A\to L\to L)\to L\to L\,\,\sin\\
  & \slet\,map : \{A\,B : \U\}\to (A \to B) \to List\,A \to List\,B\\
  & \hspace{1em}=
  \lambda\,\{A\}\,\{B\}\,f\,as\,L\,cons\,nil.\,as\,L\,(\lambda\,a.\,cons\,(f\,a))\,nil\,\,\sin\\
  & map\,\{\U\}\,\{\U\}\,(\lambda\,A.\, A \to A)\,(\lambda\,L\,cons\,nil.\,cons\,\U\,(cons\,\U\,nil))
\end{alignat*}
In the core syntax, all applications must be explicit. In the surface syntax we
will be able to omit implicit arguments to $map$.

\end{example}

\subsection{Metasubstitutions}

Before we can move on to the description of the elaborator, we need to specify
metasubstitutions. These are essentially just parallel substitutions of
metacontexts, and their purpose is to keep track of meta-operations (e.g.\ fresh
meta creation or solution of a meta).

\begin{itemize}
  \item
    A metasubstitution $\boxed{\theta : \Theta_0 \To \Theta_1}$ assigns to each variable
    in $\Theta_1$ a term in $\Theta_0$ , hence it is represented as a list of
    terms $(\alpha_1 \mapsto t_1,\,...\,\,\alpha_i \mapsto t_i)$.
  \item
    We define the action of a metasubstitution on contexts and terms by
    recursion; we notate action on contexts as $\Gamma[\theta]$ and action on
    terms as $t[\theta]$. We remark that there is no abstraction for
    metavariables in the core syntax, so we do not have to handle variable
    capture (or index shifting).
\end{itemize}
The following are admissible:
\begin{mathpar}
  \inferrule*[lab=metasub/empty]
             {\Theta_0\vdash}
             {() : \Theta_0\To \emptycon}

  \inferrule*[lab=metasub/extended]
             {\theta : \Theta_0\To\Theta_1 \\ \Theta_0|\emptycon\vdash t : A[\theta]}
             {(\theta,\, \alpha\mapsto t) : \Theta_0\To(\Theta_1,\,\alpha : A)}

  \inferrule*[lab=metasub/con-action]
             {\Theta_1|\Gamma\vdash \\ \theta : \Theta_0\To\Theta_1}
             {\Theta_0|\Gamma[\theta]\vdash}

  \inferrule*[lab=metasub/tm-action]
             {\Theta_1|\Gamma\vdash t : A \\ \theta : \Theta_0\To\Theta_1}
             {\Theta_0|\Gamma[\theta] \vdash t[\theta] : A[\theta]}

  \inferrule*[lab=metasub/identity]
             {\\}
             {\id : \Theta\To\Theta}

  \inferrule*[lab=metasub/composition]
             {\theta_{0} : \Theta_1 \To \Theta_2 \\ \theta_1 : \Theta_0 \To \Theta_1}
             {\theta_0 \circ \theta_1 : \Theta_0 \To \Theta_2}

  \inferrule*[lab=metasub/weakening]
             {\\}
             {\p : (\Theta,\,x : A) \To \Theta}
\end{mathpar}

The identity substitution $\id$ maps each variable to itself. Composition is
given by pointwise term substitution, $\id$ and $\blank\circ\blank$ yields a
category, and the action of metasubstitution on contexts and terms is
functorial. The weakening substitution $\p$ (the naming comes from
categories-with-families terminology \cite{dybjer1995internal}) can be defined
as dropping the last entry from $\id : (\Theta,\,x : A) \To (\Theta,\,x : A)$.

\subsection{Fresh Metavariables}

Using \emph{contextual metavariables} is a standard practice in the
implementation of dependently typed languages. This means that every ``hole'' in
the surface language is represented as an unknown function which abstracts over
all bound variables in the scope of a hole. Unlike \cite{nanevski2008contextual}
and similarly to \cite{gundry2013type}, we do not have a first-class notion of
contextual types, and instead reuse the standard dependent function type to
abstract over enclosing contexts.

\begin{definition}[Closing type] For each $\Theta|\Gamma \vdash A : \U$, we define
$\Gamma \To A$ by recursion on $\Gamma$, such that $\Theta|\emptycon\vdash
  \Gamma \To A : \U$.
  \begin{alignat*}{3}
    &((\Gamma,\, x : A) \To B)     && :\equiv (\Gamma \To ((x : A) \to B))\\
    &((\Gamma,\, x : A = t) \To B) && :\equiv (\Gamma \To B[x\mapsto t])\\
    &(\emptycon \To B)             && :\equiv B
  \end{alignat*}
\end{definition}

\begin{definition}[Contextualization] For each $\Theta|\Gamma \vdash t : \Gamma\To A$,
we define the spine $\overline{\mathsf{vars}_{\Gamma}}$ such that that
$\Theta|\Gamma\vdash t\,\overline{\mathsf{vars}_{\Gamma}} : A$. Informally, this
is $t$ applied to all bound variables in $\Gamma$.
  \begin{alignat*}{3}
    &(t\,\overline{\mathsf{vars}_{\Gamma,\,x:A}})   && :\equiv (t\,\overline{\mathsf{vars}_{\Gamma}})\,x \\
    &(t\,\overline{\mathsf{vars}_{\Gamma,\,x:A=t}}) && :\equiv (t\,\overline{\mathsf{vars}_{\Gamma}}) \\
    &(t\,\overline{\mathsf{vars}_{\emptycon}})     && :\equiv t
  \end{alignat*}
\end{definition}

\begin{example} If we have $\Gamma \equiv (\emptycon,\,A : \U,\,B : A \to \U)$, then
$(\Gamma \To \U) \equiv ((A : \U)(B : A \to \U) \to \U)$ and
$t\,\overline{\mathsf{vars}_{\Gamma}} \equiv t\,A\,B$.
\end{example}

\begin{definition}[Fresh meta creation] We specify $\freshMeta{\Theta}{\Gamma}{A}$ as follows:
  \begin{mathpar}
  \inferrule*{\Theta|\Gamma\vdash A : \U}
             {\freshMeta{\Theta}{\Gamma}{A} \in \{(\Theta',\,\theta,\,t)\,|\,(\theta : \Theta' \To \Theta)\,\land\,(\Theta'|\Gamma[\theta]\vdash t : A[\theta])\}}
  \end{mathpar}
The definition $\freshMeta{\Theta}{\Gamma}{A} :\equiv ((\Theta,\,\alpha:\Gamma\To
A),\,\p,\,\alpha\,\overline{\mathsf{vars}_{\Gamma}})$, where $\alpha$ is fresh in
$\Theta$, satisfies this specification. We extend $\Theta$ with a fresh meta,
which has the closing type $\Gamma \To A$. The $\p$ weakening relates the new
metacontext to the old one, by ``dropping'' the new entry. Lastly,
$\alpha\,\overline{\mathsf{vars}_{\Gamma}}$ is the new meta
applied to all bound variables.
\end{definition}

\subsection{Implicit Argument Insertion}

We define a helper function which inserts implicit applications around a core
term. For example, if we have a defined name $id$ with type $\{A : \U\}\to A \to
A$ occurring in the surface program, we usually want to expand $id$ to
$id\,\{\alpha\}$, where $\alpha$ is a fresh metavariable.
\begin{mathpar}
\inferrule*{ins \in \{\true,\,\false\} \\ \Theta|\Gamma\vdash t : A}
           {\einsert{ins}{\Theta}{\Gamma}{t}{A} \in \{(\Theta',\,\theta\,t',\,A')\,|\,
             (\theta : \Theta' \To \Theta)\,\land\,(\Theta'|\Gamma[\theta]\vdash t' : A')\}}
\end{mathpar}
We have an additional $ins \in \{\true,\,\false\}$ parameter, which simply
toggles whether any insertion is to be performed. We will use this in the
definition of elaboration. Insertion is defined by recursion on $ins$ and the
$A$ type, as follows.
\begin{alignat*}{3}
  &\einsert{\false}{\Theta}{\Gamma}{t}{A} && :\equiv\,\,&& (\Theta,\,\id,\,t,\,A)\\
  &\einsert{\true\,}{\Theta}{\Gamma}{t}{(\{x : A\}\to B)} && :\equiv&&
       \slet\,(\Theta',\,\theta,\,u) = \freshMeta{\Theta}{\Gamma}{A}\\
  & && &&\sin\,\einsert{\true}{\Theta'}{(\Gamma[\theta])}{((t[\theta])\,\{u\})}{(B[\theta][x\mapsto u])}\\
  &\einsert{\true\,}{\Theta}{\Gamma}{t}{A} && :\equiv&& (\Theta,\,\id,\,t,\,A)
\end{alignat*}

\subsection{Unification}

We assume that there is a unification procedure, which returns a unifying
metasubstitution on success. We only have \emph{homogeneous} unification,
i.e.\ the two terms to be unified must have the same type. The specification is
as follows:
\begin{mathpar}
\inferrule*{\Theta|\Gamma\vdash t : A \\ \Theta|\Gamma\vdash u : A}
           {\unify\,t\,u \in \{(\Theta',\,\theta)\,|\,(\theta : \Theta' \To \Theta)
             \,\land\,(\Theta'|\Gamma[\theta]\vdash
             t[\theta] \equiv u[\theta] : A[\theta])\}\,\cup\,\{\fail\}}
\end{mathpar}

Here, we do not require that unification returns most general unifiers, nor do
we go into the details of how unification is implemented. Gundry describes
unification in detail in \cite[Chapter~4]{gundry2013type} for a similar syntax,
with a similar (though more featureful) setup for metacontexts.

\todo{example for meta solution, more references, describe at least pattern unif and pruning briefly}

Note that our unification algorithm does not support \emph{constraint
  postponing}, since we have not specified constraints. In our concrete
implementation, unification supports basic higher-order pattern unification and
metavariable pruning \cite{TODO}.

\subsection{Elaboration}

In this section we define the elaboration algorithm. First, we explain the used notations.

\begin{itemize}
  \item We use a Haskell-like monadic pseudocode notation, where the side effect is
    failure via $\fail$.
  \item We use pattern matching notation on core terms; e.g.\ we may match on
    whether a type is a function type. This requires an evaluation/normalization
    procedure on core terms, but we already assume this in unification.
\end{itemize}

Elaboration consists of two (partial) functions, checking and inferring, which
are defined by mutual induction on surface syntax. They are specified as
follows. We also have the additional $ins \in \{\true,\,\false\}$ argument for
inference, which toggles whether the output has inserted implicit arguments.  We
explain the cases of the definition in order.

\begin{mathpar}
\inferrule*[lab=checking]
           {\text{$t$ is a surface expression} \\ \Theta|\Gamma \vdash A : \U}
           {\echeck{t}{\Theta}{\Gamma}{A} \in
             \{(\Theta',\,\theta,\,t')\,|\,(\theta : \Theta' \To \Theta)\,\land\,
               (\Theta'|\Gamma[\theta]\vdash t' : A[\theta])\}\cup\{\fail\}
           }

\inferrule*[lab=inferring]
           {ins \in \{\true,\,\false\} \\
                \text{$t$ is a surface expression} \\ \Theta|\Gamma \vdash}
           {\einfer{t}{ins}{\Theta}{\Gamma} \in
             \{(\Theta',\,\theta,\,t',\,A)\,|\,(\theta : \Theta' \To \Theta)\,\land\,
               (\Theta'|\Gamma[\theta]\vdash t' : A)\}\cup\{\fail\}
           }
\end{mathpar}

\begingroup
\allowdisplaybreaks
\begin{alignat*}{3}
  &\echeck{\lambda\,x.\,t}{\Theta}{\Gamma}{((x : A)\to B)} :\equiv \edo \\
  &\quad(\Theta',\,\theta,\,t') \leftarrow \echeck{t}{\Theta}{(\Gamma,\,x:A)} B\\
  &\quad\ereturn\,(\Theta',\,\theta,\,\lambda\,x.\,t')\\
  &\echeck{\lambda\,\{x\}.\,t}{\Theta}{\Gamma}{(\{x : A\}\to B)} :\equiv \edo \\
  &\quad(\Theta',\,\theta,\,t') \leftarrow \echeck{t}{\Theta}{(\Gamma,\,x:A)} B\\
  &\quad\ereturn\,(\Theta',\,\theta,\,\lambda\,\{x\}.\,t')\\
  &\echeck{t}{\Theta}{\Gamma}{(\{x : A\}\to B)} : \equiv \edo \\
  &\quad (\Theta',\,\theta,\,t') \leftarrow \echeck{t}{\Theta}{(\Gamma,\,x:A)} B\\
  &\quad (\Theta',\,\theta,\,\lambda\,\{x\}.\,t')\\
  &\echeck{\slet\,x:A=t\,\sin\,u}{\Theta_0}{\Gamma}{B} :\equiv \edo \\
  &\quad(\Theta_1,\,\theta_1,\,A') \leftarrow \echeck{A}{\Theta_0}{\Gamma}{\U}\\
  &\quad(\Theta_2,\,\theta_2,\,t') \leftarrow \echeck{t}
                {\Theta_1}{(\Gamma[\theta_1])}{A'}\\
  &\quad(\Theta_3,\,\theta_3,\,u') \leftarrow
                \echeck{u}{\Theta_2}{(\Gamma[\theta_1\circ\theta_2])}{(B[\theta_1\circ\theta_2])}\\
  &\quad\ereturn\,(\Theta_3,\,\theta_1\circ\theta_2\circ\theta_3,\,\slet\,x:A'[\theta_2\circ\theta_3]=t'[\theta_3]\,\sin\,u')\\
  &\echeck{\_}{\Theta}{\Gamma}{A} :\equiv \edo \\
  &\quad\ereturn\,(\freshMeta{\Theta}{\Gamma}{A})\\
  &\echeck{t}{\Theta_0}{\Gamma}{A} :\equiv \edo \\
  &\quad(\Theta_1,\,\theta_1,\,t',\,B) \leftarrow \einfer{t}{\true}{\Theta_0}{\Gamma}\\
  &\quad(\Theta_2,\,\theta_2) \leftarrow \unify\,(A[\theta_1])\,B\\
  &\quad\ereturn\,(\Theta_2,\,\theta_1\circ\theta_2,\,t'[\theta_2])\\\\
  &\einfer{x}{ins}{\Theta}{\Gamma} :\equiv \edo\\
  &\quad\eif\,(x : A \in \Gamma)\,\lor\,(x : A = t \in \Gamma) \\
  &\qquad   \ethen\, \ereturn\,(\einsert{ins}{\Theta}{\Gamma}{x}{A})\\
  &\qquad   \eelse\, \fail\\
  &\einfer{\U}{ins}{\Theta}{\Gamma} :\equiv \edo\\
  &\quad\ereturn\,(\Theta,\,\id,\,\U,\,\U)\\
  &\einfer{(x : A)\to B}{ins}{\Theta_0}{\Gamma} :\equiv \edo\\
  &\quad(\Theta_1,\,\theta_1,\,A') \leftarrow \echeck{A}{\Theta_1}{\Gamma}{\U}\\
  &\quad(\Theta_2,\,\theta_2,\,B') \leftarrow
                 \echeck{B}{\Theta_2}{(\Gamma[\theta_1],\,x : A')}{\U}\\
  &\quad\ereturn\,(\Theta_2,\,\theta_1\circ\theta_2,
                 \,((x : A'[\theta_2])\to B'),\,\U)\\
  &\einfer{\{x : A\}\to B}{ins}{\Theta_0}{\Gamma} :\equiv \edo\\
  &\quad(\Theta_1,\,\theta_1,\,A') \leftarrow \echeck{A}{\Theta_1}{\Gamma}{\U}\\
  &\quad(\Theta_2,\,\theta_2,\,B') \leftarrow
                 \echeck{B}{\Theta_2}{(\Gamma[\theta_1],\,x : A')}{\U}\\
  &\quad\ereturn\,(\Theta_2,\,\theta_1\circ\theta_2,
                 \,(\{x : A'[\theta_2]\}\to B'),\,\U)\\
  &\einfer{\lambda\,x.\,t}{ins}{\Theta_0}{\Gamma} :\equiv \edo \\
  &\quad(\Theta_1,\,\theta_1,\,A)\leftarrow \freshMeta{\Theta}{\Gamma}{\U}\\
  &\quad(\Theta_2,\,\theta_2,\,t',\,B)\leftarrow \einfer{t}{\true}{\Theta_1}{(\Gamma[\theta_1],\,x:A)}\\
  &\quad\ereturn\,(\Theta_2,\,\theta_1\circ\theta_2,\,\lambda\,x.\,t',\,(x : A[\theta_2])\to B)\\
  &\einfer{\lambda\,\{x\}.\,t}{ins}{\Theta_0}{\Gamma} :\equiv \edo \\
  &\quad(\Theta_1,\,\theta_1,\,A)\leftarrow \freshMeta{\Theta}{\Gamma}{\U}\\
  &\quad(\Theta_2,\,\theta_2,\,t',\,B)\leftarrow \einfer{t}{\true}{\Theta_1}{(\Gamma[\theta_1],\,x:A)}\\
  &\quad\ereturn\,(\einsert{ins}{\Theta_2}{(\Gamma[\theta_1\circ\theta_2])}{(\lambda\,\{x\}.\,t')}{(\{x : A[\theta_2]\}\to B)})\\
  &\einfer{t\,u}{ins}{\Theta_0}{\Gamma} :\equiv \edo \\
  &\quad (\Theta_1,\,\theta_1,\,t',\,A) \leftarrow \einfer{t}{\true}{\Theta_0}{\Gamma}\\
  &\quad \ecase\,\,A\,\,\eof\\
  &\qquad   ((x : A)\to B) \To \edo\\
  &\qquad\quad  (\Theta_2,\,\theta_2,\,u') \leftarrow
                    \echeck{u}{\Theta_1}{(\Gamma[\theta_1])}{A}\\
  &\qquad\quad  \ereturn\,(\einsert{ins}{\Theta_2}{(\Gamma[\theta_1\circ\theta_2])}{(t'[\theta_2]\,u')}{(B[\theta_2][x\mapsto u'])})\\
  &\qquad A \To \fail\\
  &\einfer{t\,\{u\}}{ins}{\Theta_0}{\Gamma} :\equiv \edo \\
  &\quad (\Theta_1,\,\theta_1,\,t',\,A) \leftarrow \einfer{t}{\false}{\Theta_0}{\Gamma}\\
  &\quad \ecase\,\,A\,\,\eof\\
  &\qquad   (\{x : A\}\to B) \To \edo\\
  &\qquad\quad  (\Theta_2,\,\theta_2,\,u') \leftarrow
                    \echeck{u}{\Theta_1}{(\Gamma[\theta_1])}{A}\\
  &\qquad\quad  \ereturn\,(\einsert{ins}{\Theta_2}{(\Gamma[\theta_1\circ\theta_2])}{(t'[\theta_2]\,\{u'\})}{(B[\theta_2][x\mapsto u'])})\\
  &\qquad A \To \fail\\
  &\einfer{\slet\,x:A=t\,\sin\,u}{ins}{\Theta_0}{\Gamma} :\equiv \edo \\
  &\quad(\Theta_1,\,\theta_1,\,A') \leftarrow \echeck{A}{\Theta_0}{\Gamma}{\U}\\
  &\quad(\Theta_2,\,\theta_2,\,t') \leftarrow \echeck{t}
                {\Theta_1}{(\Gamma[\theta_1])}{A'}\\
  &\quad(\Theta_3,\,\theta_3,\,u',\,B) \leftarrow
                \einfer{u}{ins}{\Theta_2}{(\Gamma[\theta_1\circ\theta_2])}\\
  &\quad\ereturn\,(\Theta_3,\,\theta_1\circ\theta_2\circ\theta_3,\,(\slet\,x:A'[\theta_2\circ\theta_3]=t'[\theta_3]\,\sin\,u'),\,B)\\
  &\einfer{\_}{ins}{\Theta}{\Gamma} :\equiv \edo \\
  &\quad \slet\,(\Theta',\,\theta,\,A) = \freshMeta{\Theta}{\Gamma}{\U}\\
  &\quad \ereturn\,(\freshMeta{\Theta'}{(\Gamma[\theta])}{A})\\
\end{alignat*}
\endgroup

\subsubsection{Checking}
The first two clauses are checking $\lambda$-s, where the expected type exactly
matches the $\lambda$ expressions. Hence, we simply check under binders with
$\echeck{t}{\Theta}{(\Gamma,\,x:A)} B$, and wrap the resulting term in the
appropriate $\lambda$.

The third clause for $\echeck{t}{\Theta}{\Gamma}{(\{x : A\}\to B)}$ is more
interesting. Here, we are checking a surface term which is \emph{not} a
$\lambda$ (this follows from our top-down pattern matching notation), with an
implicit function expected type. Here, we check $t$ in the extended $\Gamma,\,x
: A$ context, and we insert a new implicit $\lambda$ in the elaboration
output. This is the only point where implicit $\lambda$-s are introduced by
elaboration. Practically, this rule is commonly useful whenever we have a
higher-order function where some arguments have implicit function type. For
example, in the surface syntax, assume natural numbers, and an induction
principle for them:
\[
NatInd : \{P : \Nat \to \U\}\to \,P\,\zero \to (\{n : \Nat\}\to P\,n \to
         P\,(\suc\,n)) \to (n : \Nat) \to P\,n
\]
Then, define addition using induction:
\begin{alignat*}{1}
& \slet\, NatPlus : \Nat \to \Nat \to \Nat\\
& \qquad = NatInd\,(\lambda\,n.\,\Nat\to\Nat)\,(\lambda\,m.\,m)\,
                        (\lambda\,f\,m.\,\suc\,(f\,m))\,\,\sin\,\,...
\end{alignat*}
When the above is elaborated, the $\lambda\,f\,m.\,\suc\,(f\,m)$ function is
checked with the expected type $\{n : \Nat\}\to (\Nat \to \Nat) \to (\Nat \to
\Nat)$, and the elaboration output is $\lambda\,\{n\}\,f\,m.\,\suc\,(f\,m)$.
Hence, in this case we do not have to write implicit $\lambda$ in the surface
syntax.

For $\echeck{\slet\,x:A=t\,\sin\,u}{\Theta_0}{\Gamma}{B}$, we simply let
checking fall through. The definition here is a bit noisy, because we need to
thread metasubstitutions through, and we always have to ``update'' core terms
and contexts with the current metasubstitution.

For $\echeck{\_}{\Theta}{\Gamma}{A}$, we return a fresh metavariable with the
expected type. In any other $\echeck{t}{\Theta_0}{\Gamma}{A}$ case, we have a
\emph{change of direction}: we infer a type for $t$, then unify the expected and
inferred types.

\subsubsection{Inferring}

For $\einfer{x}{ins}{\Theta}{\Gamma}$, we look up the type of $x$ in $\Gamma$,
and insert implicit applications if needed. In the case of $\U$, we always
succeed and infer $\U$ as type. In the cases for function types, we check that
the domains and codomains have type $\U$.

For $\lambda$-s, we create a fresh meta for the domain type (since our surface
$\lambda$-s are not annotated), and infer the bodies. In the case of
$\einfer{\lambda\,\{x\}.\,t}{ins}{\Theta_0}{\Gamma}$, we additionally perform
$\einsert$ on the output. \todo{explain this weird case}

The $\einfer{t\,u}{ins}{\Theta_0}{\Gamma}$ and
$\einfer{t\,\{u\}}{ins}{\Theta_0}{\Gamma}$ cases are again interesting. Here, we
first infer a type for the term which is being applied, and only proceed if the
type is an appropriate function. Note a difference between the explicit and
implicit case. In the former case, we use $\einfer{t}{\true}{\Theta_0}{\Gamma}$,
which inserts implicit applications. In the latter case we do not insert
implicit applications. This, together with the inference definition for
variables, ensures that implicit applications in the surface syntax behave
similarly as in Agda. For example, given $id : \{A : \U\}\to A\to A$ in scope,
we elaborate $id\,\U$ as follows:
\begin{enumerate}
  \item The expression is an explicit application, so we infer $\id$ and insert implicit
        arguments, returning $id\,\{\alpha\}$, where $\alpha$ is a fresh meta.
  \item We check that $\U$ has type $\alpha$. Here we immediately change direction,
        inferring $\U$ as type for $\U$ and unifying $\alpha$ with $\U$.
  \item Hence, the resulting output is $id\,\{\U\}\,\U$.
\end{enumerate}
On the other hand, we elaborate $id\,\{\U\}$ as follows:
\begin{enumerate}
  \item This is an implicit application, so we infer a type for $id$ without inserting
    implicit arguments. This yields the inferred type $\{A : \U\}\to A\to A$, and
    we check that $\U$ has type $\U$.
  \item This changes direction again, and we infer $\U$ type for $\U$, and
    successfully unify $\U$ with $\U$.
\end{enumerate}
\todo{explain that we fail if $t$ has meta-headed type or handle it in elab}

In the case of $\slet$, inference again just falls through, and we infer a type
for the $\slet$ body. For $\einfer{\_}{ins}{\Theta}{\Gamma}$, we create a fresh meta
for the type of the hole, and another fresh meta for the hole itself.

\subsubsection{On soundness, completeness, and other properties}
We briefly discuss what we can and cannot say about the presented
elaborator. First, elaboration is \emph{sound} in the sense that it never
produces malformed core syntax.

\begin{theorem}[Soundness of elaboration] The definitions of $\echeckblank$ and
$\einferblank$ conform to the specification \ref{TODO}. This follows by induction on surface syntax and analyzing the definitions, while also relying on properties of substitution, metasubstitution, $\unify$ and $\freshMeta$. \qed
\end{theorem}

We remark that this notion of soundness is only a ``sanity'' or well-typing
statement for elaboration. In fact, we could define elaboration as a constantly
failing partial function, and it would also conform to the specification. The
right way to view this, is that $\echeckblank$ and $\einferblank$ together
with their specification constitute the semantics of surface syntax. We do not
give any other semantics to the surface syntax, nor does it support any other
operation.

We do not present any \emph{completeness} result for elaboration in this
paper. For an example of what this would entail, in \cite{dunfield2013complete},
completeness means that whenever there is a way to fill in missing details in
the surface syntax, algorithmic typechecking \emph{always} finds it. In
ibid.\ this means figuring out domain types for $\lambda$-s and inserting all
implicit applications. However, our elaborator targets a far stronger theory,
and it is beyond our reach to succinctly characterize which annotations are
inferable in the surface language.

We can still say something about the behavior of our elaborator. For this, we
consider a translation from core terms to surface terms, the obvious forgetful
translation, which maps core terms to surface counterparts. Now, this is an
``evil'' construction on core terms, since it does not preserve definitional
equality. We shall only use this evil notion in the following statement.

\begin{theorem}[Conservativity]
Elaboration is conservative over the surface syntax, in the sense that for any
surface term $t$, if checking or inference outputs $t'$, then the forgetful
translation of $t'$ differs from $t$ only by
  \begin{itemize}
    \item Having all $\_$ holes filled in by expressions.
    \item Having extra implicit $\lambda$-s and implicit applications inserted.
  \end{itemize}
This follows by straightforward induction on surface syntax. \qed
\end{theorem}

\todo{Say something about termination of elab?}

Also, note that we do not support \emph{let-generalization}. This is an open
research topic in settings with dependent types, and we make no attempt at
tackling it. See \cite{eisenberg2016dependent} for a treatment in a proposed
dependent version of Haskell.

\section{Issues with First-Class Implicit Functions}

We revisit now the $polyList$ example from Section \ref{sec:introduction}. We
assume the following:
\begin{alignat*}{3}
  & List && : \U \to \U \\
  & nil  && : \{A : \U\} \to List\,A\\
  & cons && : \{A : \U\} \to A \to List\,A
\end{alignat*}
In the following, we present a trace of checking $cons\,(\lambda\,x.\,x)\,nil$
at type $List\,(\{A : \U\}\to A \to A)$. We omit context and metacontext
parameters everywhere, and notate recursive calls by indentation. We also omit
some checking, inference, implicit insertion and unification calls which are not
essential for illustration.
\begin{alignat*}{3}
  & \scriptstyle{0 }\qquad\qquad\quad && \echeckt{cons\,(\lambda\,x.\,x)\,nil}{(List\,(\{A : \U\}\to A \to A))}\\
  & \scriptstyle{1 }  && \quad \einfert{cons\,(\lambda\,x.\,x)\,nil}{\true} \\
  & \scriptstyle{2 }  && \qquad \einfert{cons\,(\lambda\,x.\,x)}{\true}\\
  & \scriptstyle{3 }  && \qquad\quad \einfert{cons}{\true}\\
  & \scriptstyle{4 }  && \qquad\quad = cons\,\{\alpha_0\}\,:\,\alpha_0 \to List\,\alpha_0 \to List\,\alpha_0\\
  & \scriptstyle{5 }  && \qquad\quad \echeckt{\lambda\,x.\,x}{\alpha_0}\\
  & \scriptstyle{6 }  && \qquad\quad = \lambda\,x.\,x\\
  & \scriptstyle{7 }  && \qquad = cons\,\{\alpha_1 \to \alpha_1\}\,(\lambda\,x.\,x) : List\,(\alpha_1\to\alpha_1) \to List\,(\alpha_1\to\alpha_1)\\
  & \scriptstyle{8 }  && \qquad \echeckt{nil}{(List\,(\alpha_1\to\alpha_1))}\\
  & \scriptstyle{9 }  && \qquad = nil\,\{\alpha_1\to\alpha_1\}\\
  & \scriptstyle{10} && \quad = cons\,\{\alpha_1 \to \alpha_1\}\,(\lambda\,x.\,x)\,(nil\,\{\alpha_1\to\alpha_1\}): List\,(\alpha_1\to\alpha_1)\\
  & \scriptstyle{11} && \quad \unify\,(List\,(\{A : \U\}\to A \to A))\,(List\,(\alpha_1\to\alpha_1))\\
  & \scriptstyle{12} && \qquad \unify\,(\{A : \U\}\to A \to A)\,(\alpha_1\to\alpha_1)\\
  & \scriptstyle{13} && \qquad = \fail
\end{alignat*}

Above, we first infer $cons\,(\lambda\,x.\,x)\,nil$, which inserts implicit
applications to fresh metas in $cons$ and $nil$, and returns $cons\,\{\alpha_1
\to \alpha_1\}\,(\lambda\,x.\,x)\,(nil\,\{\alpha_1\to\alpha_1\}) :
List\,(\alpha_1\to\alpha_1)$. Here, the $\alpha_0$ meta is refined to $\alpha_1
\to \alpha_1$ when we check $\lambda\,x.\,x$. In the end, we need to unify the
expected and inferred types, which fails, since we have an implicit function
type on one side and an explicit function on the other side.

Why does this fail? The culprit is line $\scriptstyle{5}$, where we call
$\echeckt{\lambda\,x.\,x}{\alpha_0}$. At this point, the checking type is not an
implicit function type (it is a meta), so we do not insert an implicit
$\lambda$. At the heart of the issue is that elaboration makes insertion choices
based on core types.
\begin{enumerate}
\item $\echeck{t}{\Theta}{\Gamma}{A}$ can insert a $\lambda$ only if $A$ is an implicit function type.
\item $\einsert{\true}{\Theta}{\Gamma}{A}$ inserts an application only if $A$ is an implicit function type.
\end{enumerate}
In both of these cases, if $A$ is of the form $\alpha\,\overline{u}$
(i.e.\ meta-headed), then it is possible that $\alpha$ is later refined to an
implicit function, but at that point we have already missed our shot at implicit
insertion.

At least for $\lambda$-insertion, there is a potential solution: just
\emph{postpone} checking a term until the shape of the checking type is known
for sure. This was included as part of a proposed solution for smarter
$\lambda$-insertions in \cite{johansson2015eliminating}. This means that
checking with a meta-headed type returns a ``guarded constant''
\cite[Chapter~3]{norell07thesis}, an opaque stand-in which only computes to an
actual core term when the checking type becomes known. In practice, this
solution has a painful drawback: \emph{we get no information at all from checked
  terms before the guard is unblocked}. For an example for unexpected behavior
with this solution, let us assume $Bool : \U$ and $true : Bool$, and try to
infer type for the following surface term:
\begin{alignat*}{2}
  \slet\,x : \_ = true\,\sin\, x
\end{alignat*}
We first insert a fresh meta $\alpha$ for the hole, and then check $true$ with
$\alpha$. We postpone this checking, returning a guarded constant, and then
infer a type for $x$, which is $\alpha$. Hence, this small example yields an
unsolved meta and a guarded constant in the output.

Now, this particular example can be repaired by special-casing the elaboration
of a $\slet$-definition without an explicit type annotation. However, the
current author's experience from playing with an implementation of this
solution, is that we are missing too much information by postponing, and this
cascades in an unfortunate way: postponing yields more unsolved metas, which
cause more postponing.

\section{Telescopes and Strictly Curried Functions}














\begin{acks}
  This work was supported by the European Union, co-financed by the
  European Social Fund (EFOP-3.6.3-VEKOP-16-2017-00002) and COST Action
  EUTypes CA15123.
\end{acks}




%% Bibliography
\bibliography{references}


\end{document}
